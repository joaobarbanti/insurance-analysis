##  üìÇ An√°lise de empr√©stimos 

### Projeto com o intuito de utilizar modelos de machine learning para aprovar ou reprovar empr√©stimos a partir de dados chave como renda, idade, escolaridade, sexo e etc.

## üíª Processo T√©cnico

####  Antes de inserir os dados nos modelos(e come√ßar a divers√£o) precisei realizar um pequeno tratamento no conjunto. Primeiro preenchi os dados faltantes com a m√©dia ou mediana dos dados restantes de mesma categoria, pude fazer isso sem alterar de forma demasiada o resultado, pois a porcentagem de tais dados missing ficava em torno de 8% a 10%(porcentagem pequena) caso esse n√∫mero fosse maior aplicaria outra estrat√©gia. 
#### Logo em seguida peguei os dados em forma de texto e converti os mesmos para modelo bin√°rio utilizando a fun√ß√£o get_dummies do pandas, essa etapa √© necess√°ria pois modelos de machine learning s√£o basicamente t√©cnicas de estat√≠stica e para as mesmas operarem elas precisam de dados n√∫mericos por isso √© necess√°rio a etapa de convers√£o. 
#### Com os dados ajustados, testei alguns modelos padr√µes sem nenhum tipo de refinamento para ver o resultado(ficou em torno de 80% superior do que se utilizasse a m√©dia para previs√£o) e logo depois projetei uma pipeline que pega cada modelo e seus par√¢metros e os testa na fun√ß√£o GridSearchCv e depois retorna o melhor modelo com seus melhores par√¢metros, depois disso √© s√≥ conferir esse modelo com os dados de teste e ver o resultado que nesse caso foi 93% melhor que se tivesse usado a m√©dia como previs√£o e teve 17544 verdadeiros positivos e 3622 verdadeiros negativos um resultado o tanto quanto satisfat√≥rio

## üíª Tecnologias Usadas

##### Todos modelos utilizados foram modelos de classifica√ß√£o por se tratar de um problema de aprovar ou n√£o aprovar(1,0)
##### Utilizei a biblioteca pandas e scikit-learn
##### O modelo que mais performou foi o modelo gradient-boosting a qual sua principal fun√ß√£o √© aprender com seus erros de previs√£o e assim criar √°rvores de decis√µes aprimoradas com os erros de suas anteriores









